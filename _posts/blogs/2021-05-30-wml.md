---
layout: post
title:  Policy Search > Relative Entropy Policy Search 
date: 2018-01-24
tag: Reinforcement Learning
use_math: True
---

### Gaussian policy 
There are three different kind of Gaussian policy discussed in the survey [A survey on policy search for robotics].

> * Gaussian Policy with Constant Mean, Constant Variance 
    * $$
      \begin{eqnarray}
      \pi_{\boldsymbol{\theta}}(\boldsymbol{a}) = \mathcal{N} \boldsymbol{(a \mid \mu, \Sigma)}
      \end{eqnarray}
      $$
* Gaussian Policy with Linear Mean, State-independent Variance
    * $$
      \begin{eqnarray}
      \pi_{\boldsymbol{\theta}}(\boldsymbol{a \mid s}) = \mathcal{N} \boldsymbol{(a \mid W^T \phi(s), \Sigma)}
      \end{eqnarray}
      $$
* Gaussian Policy with Linear Mean, State-Dependent Variance. [Rarely Used]
    * $$
      \begin{eqnarray}
      \pi_{\boldsymbol{\theta}}(\boldsymbol{a \mid s}) = \mathcal{N} \boldsymbol{(a \mid W^T \phi(s), \phi(x)\Sigma\phi(s) )}
      \end{eqnarray}
      $$

### REPS

#### 1. Objective function
The **Goal** is to maximize the expected return by adapting a parameterized policy. 

$$
\begin{eqnarray}
J_{\boldsymbol{\theta}} &=& \mathbb{E}[\mathcal{R_{\boldsymbol{sa}}}] = \int \int \mu^{\pi}(\boldsymbol{s})\pi_{\boldsymbol{\theta}}(\boldsymbol{a \mid s})\mathcal{R_{\boldsymbol{sa}}}dsda \quad \text{Objective Function}
\end{eqnarray}
$$

where, $\mu^{\pi}(\boldsymbol{x})$ is the state visit distribution of policy $\pi$.

#### 2. Constraints for the State Distribution
The objective of the optimization problem is given above, which is supposed to be maximized with respect to $\mu^{\pi}\pi_{\theta}(a|s)$. The state distribution $\mu^{\pi}(s)$ of the policy has to be constrained by policy $\pi_{\theta}(a|s)$ and the system dynamics $\mathcal{P_{ss'}^a}$.

$$
\begin{eqnarray}
\forall s': \mu^{\pi}(s') = \int_{s,a} \mu^{\pi}(s)\pi_{\theta}(a \mid s)\mathcal{P_{ss'}^a}dsda
\end{eqnarray}
$$

In continuous state spaces, we introduce state features $\phi(s)$ and only match the feature averages. Additionally, we require the joint probability $p(s,a) = \mu^{\pi}(s)\pi(a \mid s)$ to define a probability distribution, its intergral has to sum up to 1. 

$$
\begin{eqnarray}
\int \phi(s')\mu^{\pi}(s')ds' &=& \int \int \int \mu^{\pi} \pi(a \mid s) \mathcal{P_{ss'}^{a}} \phi(s')dsdads' \quad \text{Constraint 1}\\
1 &=& \int \int \mu^{\pi}(s)\pi(a \mid s)dsda \quad \text{Constraint 2}
\end{eqnarray}
$$

#### 3. Information Theoratic Constraints for Policy Update
One important feature of effective policy search methods is to limit the loss information between policy update. When we try to maximize the average reward of new policy, we also want to stay close to the data, i.e., the ***state-action distribution $q(s, a)$*** of the old policy. [Note, $q(s, a) != Q(s, a)$, which is called as Q-function.]

The constraint for policy update is defined by limiting the Kullback-Leibler (KL) divergence between the sampled data distribution $q(s,a)$ and the next policy $\mu^{\pi}(s)\pi(a \mid s)$.

$$
\begin{eqnarray}
\epsilon \geq D_{KL}(\mu^{\pi}(s)\pi(a \mid s) || q(s,a)) = \int \int \mu^{\pi}(s)\pi(a \mid s) \frac{\mu^{\pi}(s)\pi(a \mid s)}{q(s,a)} dsda \quad \text{Constraint 3}
\end{eqnarray}
$$

#### 4. Results
Minimizing the objective function under the constraints of constraints 1,2,3 yields the optimizing problem that defines the REPS algorithm. The close form solution for $\mu^{\pi}\pi(a \mid s)$ that can be derived by the method of Lagrangian multipliers. 

$$
\begin{eqnarray}
\mu^{\pi}(s) \pi(a \mid s) \propto q(s,a)\exp(\frac{\mathcal{R_{sa}} + \mathbb{E[v^T\phi(s')]} - \theta^T\phi(s)}{\eta})
\end{eqnarray}
$$

where $\eta$ and $v$ are Lagrangian parameters that are obtained by minimizing the dual function. 

$$
\begin{eqnarray}
g(\eta, \theta) = \eta \epsilon + \eta \log \int \int q(s,a) \exp (\frac{\mathcal{R_{sa}} + \mathbb{E}[V(s')] - V(s)}{\eta}) dsda
\end{eqnarray}
$$

### Sample-Based REPS
The distribution of state-action from data can have an arbitrary structure, we can approximate it by sampling from the data. We can represent the policy $\pi_{\theta}(a \mid s)$ as a Guassian distribution with linear mean of the linear combination of state features, $\pi_{\theta}(a \mid s; W, \Sigma) = \mathcal{N(a \mid W^T\phi(s), \Sigma)}$, where $\theta = [W, \Sigma ]$ denote the parameters to be optimized. By minimizing the KL divergence, we have

$$
\begin{eqnarray}
&&\underset{\boldsymbol{W, \Sigma}}{\mathrm{argmin}} \int p(s) D_{KL}(\pi(a \mid s) || \pi(a \mid s; W, \Sigma)) \\
&=& \underset{\boldsymbol{W, \Sigma}}{\mathrm{argmin}}  \int p(s) \int \pi(a \mid s) \log \frac{\pi(a|s)}{\pi(a|s;W,\Sigma)} dads \\
&\approx& \underset{\boldsymbol{W, \Sigma}}{\mathrm{argmax}} \sum_{i} \frac{p(s_i, a_i)}{q(s_i, a_i)} \log \pi(a_i|s_i; W, \Sigma) \\
&\approx& \underset{\boldsymbol{W, \Sigma}}{\mathrm{argmax}} \sum_{i} \omega_i \log \pi(a_i|s_i; W, \Sigma)
\end{eqnarray}
$$

where,

$$
\begin{eqnarray}
\omega_i = \exp(\frac{r(s_i, a_i) + \mathbb{E}[v^T\phi(s') |s_i, a_i] - v^T\phi(s_i)}{\eta})
\end{eqnarray}
$$

Since the available samples are drawn from the distribution $q(s,a)$, and not $p(s,a)$, we need to perform **Impotance Sampling** and divide by the **sampling distribution $q(s,a)$**.

#### **Algorithm**

> * Step 1 **Initialize the policy, a Gaussian policy with linear mean.**
    * $\pi_{\boldsymbol{\theta_0}} = \mathcal{N}\boldsymbol{(a \mid W_0^T\phi(s), \Sigma_0)}$, where $\boldsymbol{\theta_0 = \[W_0, \Sigma_0\]}$, 
    * Scalar features, $\phi(\boldsymbol{s}) = \[s\]$ 
* Step 2 **Define Value function**
    * $V_v = \boldsymbol{v}^T\psi(s)$
    * Polynomial features, $\psi(\boldsymbol{s}) = \[1, s, s^2\]$
* Step 3 **Sample N transitions, data set $\mathcal{D_{i=1,2,...N}} = \boldsymbol{(s^{[i]}, a^{[i]}, r^{[i]}, s'^{[i]})}$**
* Step 4 **Compute Advantage $A(s, a)$ or so-called Bellman Error $\delta_v$**
    * $A_{v} (s, a) = r(s, a) + \sum \mathcal{P}(s' \mid s, a)V_v(s') - V_v(s) = \delta_v(s,a)$
    * Compute it by importance sampling ?
    * $$
      \begin{eqnarray}
      A_v (s_i, a_i) = \frac{\tilde{r}(s^{[i]}, a^{[i]}) + v^T(\psi(s'^{[i]}) -\psi(s^{[i]}) )}{n(s^{[i], a^{[i]}})}
      \end{eqnarray}
      $$
* Step 5 **Optimize dual function**
    * $[\eta, v] = \underset{\eta', v'}{\mathrm{argmin}} g(\eta', v')$ s.t. $\eta > 0$
    * $g(\eta, v) = \eta \epsilon + \eta \log (\frac{1}{N} \sum_{i=1}^{N}\exp(\frac{\delta_{v}^{[i]}}{\eta}))$
* Step 6 **Policy Update** by Weighted Maximum Likelihood estimate
    * $$
      \begin{eqnarray}
      \boldsymbol{\theta}_{k+1} &=& [\boldsymbol{W_{\text{new}}, \Sigma_{\text{new}}}] \\
      &=& \underset{\theta}{\mathrm{argmax}} \sum_i^{N} \exp(\frac{\delta_v^{[i]}}{\eta}) \log \pi_\theta (a^{[i]} | s^{[i]}) 
      \end{eqnarray}
      $$
    * $$
      \begin{eqnarray}
      \boldsymbol{W_{\text{new}} = (\Phi^T D \Phi)^{-1}\Phi^T D A}
      \end{eqnarray}
      $$
    * $$
      \begin{eqnarray}
      \boldsymbol{\Sigma_{\text{new}}} = \frac{\sum_i^N d^{[i]} (\boldsymbol{a}^{[i]} - \boldsymbol{W}^T\phi(s^{[i]})) (\boldsymbol{a}^{[i]} - \boldsymbol{W}^T\phi(s^{[i]}))^T}{Z}
      \end{eqnarray}
      $$
    * $$
      \begin{eqnarray}
      Z = \frac{(\sum_{i=1}^N d^{[i]})^2 - \sum_{i=1}^N (d^{[i]})^2 }{\sum_{i=1}^N d^{[i]}} 
      \end{eqnarray}
      $$

### Weighted Maximum Likelihood Derivation

$$
\begin{eqnarray}
\boldsymbol{\theta}_{k+1} &=& [\boldsymbol{W_{\text{new}}, \Sigma_{\text{new}}}] \\
&=& \underset{\theta}{\mathrm{argmax}} \sum_i^{N} \exp(\frac{\delta_v^{[i]}}{\eta}) \log \pi_\theta (\boldsymbol{a}^{[i]} | \boldsymbol{s}^{[i]}) \\
&=& \underset{\theta}{\mathrm{argmax}} \sum_i^{N} d^{[i]} \log \pi_\theta (\boldsymbol{a}^{[i]} | \boldsymbol{s}^{[i]}) \\
&=&  \underset{\theta}{\mathrm{argmax}} \sum_i^{N} d^{[i]} \log \pi_\theta (\boldsymbol{a}^{[i]} | \boldsymbol{W}^T\boldsymbol{\phi(s)}, \boldsymbol{\Sigma}) \\
\end{eqnarray}
$$

**========== For the mean $\boldsymbol{W_{\text{new}}}$ ==========**

$$
\begin{eqnarray}
\nabla_{W} {\sum_i^{N} d^{[i]} \log \pi_\theta (\boldsymbol{a}^{[i]} | \boldsymbol{W}^T\boldsymbol{\phi(s)}, \boldsymbol{\Sigma})} &=& {\sum_i^{N} d^{[i]} \nabla_{W} \log \pi_\theta (\boldsymbol{a}^{[i]} | \boldsymbol{W}^T\boldsymbol{\phi(s)}, \boldsymbol{\Sigma})}  \\
&=& {\sum_i^{N} d^{[i]} \nabla_{W} \log \frac{1}{\boldsymbol{\Sigma} \sqrt{2\pi}} \exp{-\boldsymbol{\frac{(a^{[i]}-W^T\phi(s^{[i]}))^2}{2\Sigma} }}} \\
&=& {\sum_i^{N} d^{[i]} \nabla_{W} \log  \frac{1}{\sqrt{\det(2\pi\boldsymbol{\Sigma_k)}}} \exp[-\frac{1}{2} \boldsymbol{(a^{[i]} - W^T\phi(s^{[i]}))^T \Sigma^{-1} (a^{[i]} - W^T\phi(s^{[i]}))}]} \\
&=& {\sum_i^{N}d^{[i]}( 0 - \nabla_{W} \frac{1}{2} \boldsymbol{(a^{[i]} - W^T\phi(s^{[i]}))^T \Sigma^{-1} (a^{[i]} - W^T\phi(s^{[i]}))} )} \\
&=&  {\sum_i^{N} d^{[i]} (- \frac{1}{2}) * (-2\boldsymbol{\Sigma^{-1} (a^{[i]} - W^T\phi(s^{[i]}))\phi(s^{[i]})^T} )} \\
&=& 0 \\
\end{eqnarray}
$$

$$
\begin{eqnarray}
\Longrightarrow  0 &=& \sum_i^{N} d^{[i]}\frac{1}{2} * (-2\boldsymbol{\Sigma^{-1} (a^{[i]} - W^T\phi(s^{[i]}))\phi(s^{[i]})^T} ) \\
0 &=& \sum_i^{N} d^{[i]} \boldsymbol{\Sigma^{-1} (a^{[i]} - W^T\phi(s^{[i]}))\phi(s^{[i]})^T} \\ 
0 &=& \sum_i^{N} d^{[i]} [\boldsymbol{\Sigma^{-1} a^{[i]} \phi(s^{[i]}) - \Sigma^{-1} W^T\phi(s^{[i]})\phi(s^{[i]})^T} ]\\
 \sum_i^{N} d^{[i]} \boldsymbol{a^{[i]} \phi(s^{[i]})^T}  &=& \sum_i^{N} d^{[i]} \boldsymbol{ W^T \phi(s^{[i]}) \phi(s^{[i]})^T} \\
 \boldsymbol{A^T D \Phi} &=& \boldsymbol{ W^T\Phi^T D \Phi} \\
 \boldsymbol{W^T} &=& \boldsymbol{ A^T D \Phi (\Phi^T D \Phi)^{-1}}  \\
 \boldsymbol{W} &=& \boldsymbol{ (A^T D \Phi (\Phi^T D \Phi)^{-1})^T}  \\
 \boldsymbol{W} &=& \boldsymbol{ ((\Phi^T D \Phi)^{-1})^T (A^T D \Phi)^T}  \\
 \boldsymbol{W} &=& \boldsymbol{ ((\Phi^T D \Phi)^{T})^{-1} (\Phi^T D^T A)}  \\
 \boldsymbol{W} &=& \boldsymbol{ (\Phi^T D \Phi)^{-1} (\Phi^T D A)}  \\
\end{eqnarray}
$$

$$
\begin{eqnarray}
\Longrightarrow  \boldsymbol{W_{\text{new}} = (\Phi^T D \Phi)^{-1}\Phi^T D A}
\end{eqnarray}
$$

**========== For the covariance $\boldsymbol{\Sigma_{\text{new}}}$ ==========**

$$
\begin{eqnarray}
\nabla_{\Sigma} {\sum_i^{N} d^{[i]} \log \pi_\theta (\boldsymbol{a}^{[i]} | \boldsymbol{W}^T\boldsymbol{\phi(s)}, \boldsymbol{\Sigma})} &=& {\sum_i^{N} d^{[i]} \nabla_{\Sigma} \log \pi_\theta (\boldsymbol{a}^{[i]} | \boldsymbol{W}^T\boldsymbol{\phi(s)}, \boldsymbol{\Sigma})}  \\

&=& {\sum_i^{N} d^{[i]} \nabla_{\Sigma} \log \frac{1}{ (2\pi)^{k/2} \boldsymbol{|\Sigma|}^{1/2} } \exp{- \boldsymbol{\frac{(a^{[i]}-W^T\phi(s^{[i]}))^2}{2\Sigma} }}} \\

&=& {\sum_i^{N} d^{[i]} \nabla_{\Sigma} \log  \frac{1}{(2\pi)^{k/2} \boldsymbol{|\Sigma|}^{1/2}} \exp[- \frac{1}{2} \boldsymbol{(a^{[i]} - W^T\phi(s^{[i]}))^T \Sigma^{-1} (a^{[i]} - W^T\phi(s^{[i]}))}]} \\

&=& {\sum_i^{N} d^{[i]} \nabla_{\Sigma} \{ \log{(1)} - \log{(|\boldsymbol{\Sigma}|^{1/2} )} - \log{(2\pi)^{k/2}} + \exp{  ( - \frac{1}{2} \boldsymbol{(a^{[i]} - W^T\phi(s^{[i]}))^T \Sigma^{-1} (a^{[i]} - W^T\phi(s^{[i]}))} ) }\}} \\

&=& {\sum_i^{N} d^{[i]}  {[0 - 0 - \nabla_{\Sigma}\log{(|\boldsymbol{\Sigma}|^{1/2} )} ]} - \nabla_{\Sigma}( \frac{1}{2} \boldsymbol{(a^{[i]} - W^T\phi(s^{[i]}))^T \Sigma^{-1} (a^{[i]} - W^T\phi(s^{[i]}))} )} \\

&=& {\sum_i^N d^{[i]} (-\frac{1}{2} \boldsymbol{\Sigma}^{-1} + \frac{1}{2} \boldsymbol{\Sigma}^{-T}  \boldsymbol{(a^{[i]} - W^T\phi(s^{[i]})) (a^{[i]} - W^T\phi(s^{[i]}))^T } \boldsymbol{\Sigma}^{-T})} \\

&=& {\sum_i^N d^{[i]} (-\frac{1}{2} \boldsymbol{\Sigma}^{-1} + \frac{1}{2} \boldsymbol{\Sigma}^{-1}  \boldsymbol{(a^{[i]} - W^T\phi(s^{[i]})) (a^{[i]} - W^T\phi(s^{[i]}))^T } \boldsymbol{\Sigma}^{-1})}  = 0\\

\sum_i^N d^{[i]} \boldsymbol{\Sigma}^{-1} &=& \sum_i^N d^{[i]} \boldsymbol{\Sigma}^{-1}  \boldsymbol{(a^{[i]} - W^T\phi(s^{[i]})) (a^{[i]} - W^T\phi(s^{[i]}))^T } \boldsymbol{\Sigma}^{-1}\\

\boldsymbol{\Sigma} &=& \frac{\sum_i^N d{[i]} \boldsymbol{(a^{[i]} - W^T\phi(s^{[i]})) (a^{[i]} - W^T\phi(s^{[i]}))^T} }{\frac{(\sum_i^N d^{[i]})^2 - \sum_i^N(d^{[i]})^2} {\sum_i^N d^{[i]}}}  ?????????????????? \text{This is the result, I could't figure it out.}
\end{eqnarray} 
$$

Side Note: 

$$
\begin{eqnarray}
\nabla_{\Sigma}\log{( |\boldsymbol{\Sigma}|^{1/2} )} &=& \frac{\nabla_{\Sigma} (|\boldsymbol{\Sigma}|^{1/2}) }{|\boldsymbol{\Sigma}|^{1/2}}  \\
&=&  \frac{\frac{1}{2} * |\boldsymbol{\Sigma}|^{-1/2} * \nabla_{\boldsymbol{\Sigma}} |\boldsymbol{\Sigma}| }{|\boldsymbol{\Sigma}|^{1/2}} \\ 
&=& \frac{\frac{1}{2} * |\boldsymbol{\Sigma}|^{-1/2} * |\boldsymbol{\Sigma}| (\boldsymbol{\Sigma}^{-1})^T}{|\boldsymbol{\Sigma}|^{1/2}} \\
&=& \frac{1}{2} (\boldsymbol{\Sigma}^{-1})^T \\
&=& \frac{1}{2} \boldsymbol{\Sigma}^{-1}
\end{eqnarray}
$$

### Optimizing the Dual Function [Derivation]

The dual function is in (log-sum-exp) form and therefore convex in $\boldsymbol{v}$. The optimization problem we have is,

$$
\begin{eqnarray}
&\min_{\eta, \boldsymbol{v}}& \quad  g(\eta, \boldsymbol{v}) = \eta \epsilon + \eta \log \sum_{\boldsymbol{x^{[i]}, u^{[i]}}} \frac{1}{N} \exp{(\frac{\delta_{\boldsymbol{v}} (\boldsymbol{x^{[i]}, u^{[i]}})}{\eta})} \\

&\textrm{s.t.:}& \quad \eta > 0 \\ 
\end{eqnarray}
$$

For numeriacal accuracy, we usually use the log-sum-exp trick, 

$$
\begin{eqnarray}
g(\eta, \boldsymbol{v}) = \eta \epsilon + \max{\delta_v} + \eta \log \sum_{\boldsymbol{x^{[i]}, u^{[i]}}} \frac{1}{N} \exp{(\frac{\delta_{\boldsymbol{v}} (\boldsymbol{x^{[i]}, u^{[i]}}) - \max{\delta_v}} {\eta})} 
\end{eqnarray}
$$

**========== Derivation for $\eta$ ==========**

$$
\begin{eqnarray}
\nabla_{\eta} g(\eta, \boldsymbol{v}) &=& \nabla_{\eta} ( \eta \epsilon + \max{\delta_v} + \eta \log \sum_{\boldsymbol{x^{[i]}, u^{[i]}}} \frac{1}{N} \exp{(\frac{\delta_{\boldsymbol{v}} (\boldsymbol{x^{[i]}, u^{[i]}}) - \max{\delta_v}} {\eta})} ) \\
&=& \epsilon + 0 + \log \sum_{\boldsymbol{x^{[i]}, u^{[i]}}} \frac{1}{N} \exp{(\frac{\delta_{\boldsymbol{v}} (\boldsymbol{x^{[i]}, u^{[i]}}) - \max{\delta_v}} {\eta})} + \eta \nabla_{\eta} \log \sum_{\boldsymbol{x^{[i]}, u^{[i]}}} \frac{1}{N} \exp{(\frac{\delta_{\boldsymbol{v}} (\boldsymbol{x^{[i]}, u^{[i]}}) - \max{\delta_v}} {\eta})}  \\
&=&  \epsilon + \log \sum_{\boldsymbol{x^{[i]}, u^{[i]}}} \frac{1}{N} \exp{(\frac{\delta_{\boldsymbol{v}} (\boldsymbol{x^{[i]}, u^{[i]}}) - \max{\delta_v}} {\eta})} + \eta \frac{\sum 1/N \exp{(\frac{\delta_{\boldsymbol{v}} (\boldsymbol{x^{[i]}, u^{[i]}}) - \max{\delta_v}}{\eta})} * (-(\delta_{\boldsymbol{v}} (\boldsymbol{x^{[i]}, u^{[i]}}) - \max{\delta_v})/ \eta^2)}{\sum 1/N \exp{\frac{\delta_{\boldsymbol{v}} (\boldsymbol{x^{[i]}, u^{[i]}}) - \max{\delta_v}}{\eta}}} \\
&=& \epsilon + \log \sum_{\boldsymbol{x^{[i]}, u^{[i]}}} \frac{1}{N} \exp{(\frac{\delta_{\boldsymbol{v}} (\boldsymbol{x^{[i]}, u^{[i]}}) - \max{\delta_v}} {\eta})} - \frac{\sum \exp{(\delta_{\boldsymbol{v}} (\boldsymbol{x^{[i]}, u^{[i]}}) - \max{\delta_v} / \eta)} * (\delta_{\boldsymbol{v}} (\boldsymbol{x^{[i]}, u^{[i]}}) - \max{\delta_v})}{\eta \sum \exp{((\delta_{\boldsymbol{v}} (\boldsymbol{x^{[i]}, u^{[i]}}) - \max{\delta_v} )/ \eta)}} \\
&=& \epsilon + \log \sum_{i} (\frac{1}{N} Z_i) - \frac{\sum_i Z_i (\delta_{\boldsymbol{v}} (\boldsymbol{x^{[i]}, u^{[i]}}) - \max \delta_v)}{\eta \sum_i Z_i}
\quad \text{with} \quad Z_i = \exp{(\frac{\delta_{\boldsymbol{v}} (\boldsymbol{x^{[i]}, u^{[i]}}) - \max \delta_v }{\eta})}
\end{eqnarray}
$$

**========== Derivation for $\boldsymbol{v}$ ==========**

$$
\begin{eqnarray}
\nabla_{\boldsymbol{v}} g(\eta, \boldsymbol{v}) &=& \nabla_{\boldsymbol{v}} ( \eta \epsilon + \max{\delta_v} + \eta \log \sum_{\boldsymbol{x^{[i]}, u^{[i]}}} \frac{1}{N} \exp{(\frac{\delta_{\boldsymbol{v}} (\boldsymbol{x^{[i]}, u^{[i]}}) - \max{\delta_v}} {\eta})} ) \\
&=& (0 + 0 + \eta \nabla_{\boldsymbol{v}} \log \sum_{\boldsymbol{x^{[i]}, u^{[i]}}} \frac{1}{N} \exp{(\frac{\delta_{\boldsymbol{v}} (\boldsymbol{x^{[i]}, u^{[i]}}) - \max{\delta_v}} {\eta})} ) \\

&=& \eta \frac{\sum 1/N \exp{(\frac{\delta_{\boldsymbol{v}} (\boldsymbol{x^{[i]}, u^{[i]}}) - \max{\delta_v}} {\eta})} \nabla_{\boldsymbol{v}} \delta_{\boldsymbol{v}} (x^{[i]}, u^{[i]})}{\sum 1/N \exp{(\frac{\delta_{\boldsymbol{v}} (\boldsymbol{x^{[i]}, u^{[i]}}) - \max{\delta_v}} {\eta})}} \\

&=& \eta \frac{\sum_i Z_i (\mathbb{E_{p(\boldsymbol{x'|x^{[i]},u^{[i]}})}} [\varphi(\boldsymbol{x}')] - \varphi(\boldsymbol{x}^{[i]})) }{\sum_i Z_i} \quad \text{with} \quad Z_i = \exp{(\frac{\delta_{\boldsymbol{v}} (\boldsymbol{x^{[i]}, u^{[i]}}) - \max \delta_v }{\eta})}
\end{eqnarray}
$$



